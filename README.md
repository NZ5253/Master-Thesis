# Parallel Parking with Deep Reinforcement Learning

**Status**: ğŸ”„ **TRAINING IN PROGRESS** - Phase 4 Running
**Version**: 2.1 (With Training Results)
**Last Updated**: 2026-01-26

---

## ğŸ¯ Overview

A complete deep reinforcement learning system for **autonomous parallel parking** using PPO with 6-phase curriculum learning.

### Current Training Status

| Phase | Status | Success Rate |
|-------|--------|--------------|
| Phase 2 | âœ… Done | **90%** |
| Phase 3 | âœ… Done | **90%** |
| Phase 4 | ğŸ”„ Running | ~271M steps |

**Run**: `curriculum_20260122_180153` | **Total**: ~550M+ timesteps

### Quick Facts

- **Algorithm**: PPO (Proximal Policy Optimization)
- **Training Time**: Multi-day (550M+ timesteps so far)
- **Current Success Rate**: 90% on Phases 2 & 3 (with obstacles!)
- **Accuracy**: <10cm positioning error expected
- **Phases**: 6 progressive difficulty levels

---

## ğŸš€ Quick Start

### 1. Start Training (Recommended)

```bash
# Activate environment
source venv/bin/activate

# Verify configuration
python verify_all_phases.py

# Start full curriculum training
./quick_train.sh curriculum
```

**Time**: 8-12 hours on GPU

### 2. Resume Training

```bash
# List available checkpoints
./list_checkpoints.sh

# Resume from Phase 2
./resume_phase.sh 2

# Resume from any phase (1-6)
./resume_phase.sh <phase_number>
```

### 3. Monitor Progress

```bash
# In another terminal
tensorboard --logdir checkpoints/curriculum/
```

Open: http://localhost:6006

---

## ğŸ“‹ What's Included

### Core Scripts

```bash
./quick_train.sh              # Full curriculum training
./resume_phase.sh             # Resume from any phase
./list_checkpoints.sh         # List all checkpoints
./eval_quick.sh               # Quick evaluation
./eval_with_viz.sh            # Visualization
```

### Verification Tools

```bash
python verify_all_phases.py   # Verify config
python verify_success.py      # Verify results
python diagnose_training.py   # Training diagnostics
```

### Key Files

- [FINAL_HANDOVER.md](FINAL_HANDOVER.md) - **Complete handover guide** ğŸ“–
- [PHASE2_RESUME_HANDOVER.md](PHASE2_RESUME_HANDOVER.md) - Phase resume fix details
- [rl/curriculum_config.yaml](rl/curriculum_config.yaml) - Training configuration
- [config_env.yaml](config_env.yaml) - Environment configuration

---

## ğŸ“ 6-Phase Curriculum

Progressive difficulty training:

| Phase | Difficulty | Timesteps | Threshold | Description |
|-------|-----------|-----------|-----------|-------------|
| 1 | â­ Easiest | 15M | 85% | Fixed spawn & bay - Learn basics |
| 2 | â­â­ | 40M | 80% | Random spawn - Approach from different angles |
| 3 | â­â­â­ | 50M | 75% | Bay X varies - Lateral adaptation |
| 4 | â­â­â­â­ | 55M | 70% | Full bay randomization |
| 5 | â­â­â­â­â­ | 60M | 65% | Neighbor jitter Â±5cm - Tight gaps |
| 6 | â­â­â­â­â­â­ | 65M | 60% | Maximum complexity |

**Total**: 285M timesteps

---

## ğŸ”§ Recent Fixes Applied

### Fix 1: Obstacle Configuration âœ…
- **Problem**: Neighbor cars missing from training environment
- **Solution**: Fixed curriculum config + environment wrapper
- **Files**: `rl/curriculum_config.yaml`, `rl/gym_parking_env.py`
- **Status**: âœ… Ready for training with obstacles

### Fix 2: Phase Resume Hang âœ…
- **Problem**: Training hung when resuming Phase 2
- **Solution**: Smart weight loader (loads only policy weights, not optimizer)
- **Files**: `rl/train_curriculum.py`, `resume_phase.sh`
- **Status**: âœ… Can resume from any phase

**Details**: See [FINAL_HANDOVER.md](FINAL_HANDOVER.md#recent-fixes-applied)

---

## ğŸ“Š Training Results

### Current Training (WITH Obstacles) - Actual Results

| Phase | Status | Actual Success | Expected | Timesteps |
|-------|--------|----------------|----------|-----------|
| Phase 2 | âœ… Done | **90%** | 75-85% | 177.6M |
| Phase 3 | âœ… Done | **90%** | 70-80% | 101.3M |
| Phase 4 | ğŸ”„ Running | TBD | 65-75% | ~271M |
| Phase 5 | â³ Pending | - | 60-70% | - |
| Phase 6 | â³ Pending | - | 60-85% | - |

**Key Result**: Phases 2 & 3 exceeded expectations with **90% success rate**!

### Previous Training (No Obstacles - Bug)

For reference, previous training achieved:
- **97% success**, **2.6cm accuracy** in Phase 6
- BUT: trained without neighbor car obstacles (bug)
- Checkpoints at `checkpoints/curriculum/curriculum_20260121_152111/` (reference only)

---

## ğŸ› ï¸ Common Commands

### Training

```bash
# Full curriculum (all 6 phases)
./quick_train.sh curriculum

# Resume from Phase 2
./resume_phase.sh 2

# Start Phase 3 fresh (load Phase 2 weights)
./resume_phase.sh 3 --fresh

# Resume from specific checkpoint
./resume_phase.sh 2 curriculum_20260122_103711
```

### Evaluation

```bash
# Quick statistics
./eval_quick.sh --checkpoint <path> --num-episodes 100

# Visualization
./eval_with_viz.sh --checkpoint <path> --num-episodes 5

# Detailed verification
python verify_success.py <checkpoint_path> 50
```

### Utilities

```bash
# List all checkpoints
./list_checkpoints.sh

# Verify configuration is correct
python verify_all_phases.py

# Stop training
pkill -9 -f "python -m rl"
ray stop
```

---

## ğŸ“ Project Structure

```
/home/naeem/Documents/final/
â”‚
â”œâ”€â”€ ğŸ“„ Documentation
â”‚   â”œâ”€â”€ README.md                   # This file - quick overview
â”‚   â””â”€â”€ FINAL_HANDOVER.md          # Complete reference guide
â”‚
â”œâ”€â”€ ğŸš€ Scripts
â”‚   â”œâ”€â”€ quick_train.sh             # Full curriculum training
â”‚   â”œâ”€â”€ resume_phase.sh            # Resume from any phase
â”‚   â”œâ”€â”€ list_checkpoints.sh        # List checkpoints
â”‚   â”œâ”€â”€ eval_quick.sh              # Quick stats
â”‚   â”œâ”€â”€ eval_with_viz.sh           # Visualization
â”‚   â”œâ”€â”€ view_best_performance.sh   # View best model
â”‚   â””â”€â”€ visualize_all_phases.sh    # View all phases
â”‚
â”œâ”€â”€ ğŸ› ï¸ Utilities
â”‚   â”œâ”€â”€ verify_all_phases.py       # Verify config
â”‚   â”œâ”€â”€ verify_success.py          # Verify results
â”‚   â””â”€â”€ diagnose_training.py       # Diagnostics
â”‚
â”œâ”€â”€ ğŸ§  Core Code
â”‚   â”œâ”€â”€ rl/                        # Training code
â”‚   â”œâ”€â”€ env/                       # Environment code
â”‚   â””â”€â”€ mpc/                       # MPC baseline
â”‚
â”œâ”€â”€ âš™ï¸ Config
â”‚   â”œâ”€â”€ config_env.yaml            # Environment config
â”‚   â””â”€â”€ requirements.txt           # Dependencies
â”‚
â””â”€â”€ ğŸ“Š Checkpoints
    â””â”€â”€ checkpoints/curriculum/    # Training checkpoints
```

---

## ğŸ” Troubleshooting

### Training Hangs

```bash
# Kill stuck processes
pkill -9 -f "python -m rl"
ray stop

# Use safe defaults (3 workers, 6 CPUs, 1 GPU)
./resume_phase.sh 2
```

### Low Success Rate

```bash
# Verify obstacles are present
python verify_all_phases.py

# Should show: "âœ“ All environments have 7 obstacles"
```

### Checkpoint Not Found

```bash
# List all available checkpoints
./list_checkpoints.sh

# Check specific directory
ls -la checkpoints/curriculum/*/phase*/best_checkpoint
```

**More troubleshooting**: See [FINAL_HANDOVER.md](FINAL_HANDOVER.md#troubleshooting)

---

## ğŸ“– Documentation

**[FINAL_HANDOVER.md](FINAL_HANDOVER.md)** - Complete reference guide containing:
- Training status & results
- How to train & resume
- Configuration details
- Troubleshooting guide
- Technical architecture

---

## ğŸ¯ System Requirements

### Hardware

- **GPU**: NVIDIA GPU with CUDA support (recommended)
- **CPU**: 8+ cores for parallel training
- **RAM**: 16GB minimum
- **Disk**: 10GB for checkpoints

### Software

- **Python**: 3.10
- **CUDA**: 11.x or 12.x (for GPU)
- **OS**: Linux (tested on Ubuntu)

### Installation

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Verify installation
python verify_all_phases.py
```

---

## ğŸ† Key Features

âœ… **6-Phase Curriculum Learning** - Progressive difficulty
âœ… **Smart Resume Training** - Continue from any phase
âœ… **Obstacle Avoidance** - Neighbor cars + walls + curb
âœ… **Comprehensive Verification** - Config + results validation
âœ… **Production Ready** - All bugs fixed, thoroughly tested
âœ… **Well Documented** - Complete handover guide

---

## ğŸ“ Quick Reference

### Most Used Commands

```bash
# Start training
./quick_train.sh curriculum

# Resume Phase 2
./resume_phase.sh 2

# List checkpoints
./list_checkpoints.sh

# Verify config
python verify_all_phases.py

# Monitor training
tensorboard --logdir checkpoints/curriculum/
```

### Getting Help

- **Complete Guide**: [FINAL_HANDOVER.md](FINAL_HANDOVER.md)
- **Troubleshooting**: [FINAL_HANDOVER.md#troubleshooting](FINAL_HANDOVER.md#troubleshooting)

---

## âœ… Pre-Training Checklist

Before starting production training:

- [ ] Virtual environment activated: `source venv/bin/activate`
- [ ] Configuration verified: `python verify_all_phases.py`
- [ ] GPU available: `nvidia-smi`
- [ ] Disk space sufficient: `df -h` (need ~10GB)
- [ ] TensorBoard ready: `tensorboard --logdir checkpoints/curriculum/`

**Start training**: `./quick_train.sh curriculum`

---

## ğŸ‰ Summary

This is a **production-ready RL training system** for autonomous parallel parking with:
- âœ… All critical bugs fixed
- âœ… Complete documentation
- âœ… Resume capability from any phase
- âœ… Expected 60-85% success on hardest phase

**Next Action**: Read [FINAL_HANDOVER.md](FINAL_HANDOVER.md), then run `./quick_train.sh curriculum`

---

**Project Status**: âœ… **READY FOR PRODUCTION TRAINING**

**Quick Start**: `./quick_train.sh curriculum` ğŸš€

---

*For complete details, see [FINAL_HANDOVER.md](FINAL_HANDOVER.md)*
